{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NClOYOOAy9Il"
   },
   "source": [
    "# WFC3 IR Blob Classification: Modeling and Evaluation\n",
    "\n",
    "### The purpose of this notebook is to walk the user through the modeling and evaluation pipeline for the WFC3 IR Blob Classifier. In this notebook, the user will:\n",
    "\n",
    "###    3. Trains a CNN to classify if blobs are in a subframe.\n",
    "#### We train a convolutional neural network with the following initial hyperparameters:\n",
    "#### - 2 convolutional layers (1 filter to 8 filters to 16 filters)\n",
    "#### - 2 fully connected layers (16 * 64 * 64 neurons to 128 neurons to 2 neurons)\n",
    "#### - 5x5 kernel\n",
    "#### - 2x2 max pooling at the end of each convolutional layer\n",
    "#### - 2 padding on each feature map. This ensures the feature maps don't shrink after a convolution, but before a max pool\n",
    "#### - 15% and 30 % dropout regularization\n",
    "#### - Cross Entropy Loss\n",
    "#### - Adam optimizer\n",
    "#### - Batch size of 100\n",
    "#### - 5 epochs\n",
    "\n",
    "### 4. Evaluates the model's performance.\n",
    "#### We use loss, accuracy, and confusion matrices as metrics for evaluating the model's performance. In addition, we check incorrect images and plot saliency maps to further investigate how and why the model makes certain predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (Pending...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vLpc0ruzoYi"
   },
   "source": [
    "## Imports\n",
    "### This notebook also uses functions defined in the complimentary python script, wfc3_ir_blob_class_utils.py. Please read the documentation of the script for further knowledge about it's functionality under Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seIZlbrhRCC2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ginga.util.zscale import zscale\n",
    "from astropy.io import fits\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wfc3_ir_blob_class_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6yS30CmzynH"
   },
   "source": [
    "## Load data from data processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "PATH = 'saved_generated_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/combine non blob and blob sets into one training set\n",
    "train_nb = np.load('{}training_non_blob.npz'.format(PATH))\n",
    "train_b = np.load('{}training_blob.npz'.format(PATH))\n",
    "\n",
    "train_image_set = np.concatenate((train_nb['image_set'], train_b['image_set']))\n",
    "train_labels = np.concatenate((train_nb['labels'], train_b['labels']))\n",
    "\n",
    "print ('Training Image Set and Label Sizes:', train_image_set.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/combine non blob and blob sets into one validation set\n",
    "val_nb = np.load('{}validation_non_blob.npz'.format(PATH))\n",
    "val_b = np.load('{}validation_blob.npz'.format(PATH))\n",
    "\n",
    "val_image_set = np.concatenate((val_nb['image_set'], val_b['image_set']))\n",
    "val_labels = np.concatenate((val_nb['labels'], val_b['labels']))\n",
    "\n",
    "print ('Validation Image Set and Label Sizes:', val_image_set.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/combine non blob and blob sets into one test set\n",
    "test_nb = np.load('{}test_non_blob.npz'.format(PATH))\n",
    "test_b = np.load('{}test_blob.npz'.format(PATH))\n",
    "\n",
    "test_image_set = np.concatenate((test_nb['image_set'], test_b['image_set']))\n",
    "test_labels = np.concatenate((test_nb['labels'], test_b['labels']))\n",
    "\n",
    "print ('Test Image Set and Label Sizes:', test_image_set.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Check\" the contents of the data sets are what they should be\n",
    "### As of now, each data set should have 100 non blob images and 100 blob images, in that order.\n",
    "### Check: \n",
    "#### - If index < 100, label is 0 and the image shown has no blobs\n",
    "#### - If index >= 100, label is 1 and the image shown has blobs (they can be faint sometimes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, 200, size=3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=[15,5])\n",
    "axs[0].imshow(train_image_set[random_index[0]], cmap='Greys')\n",
    "axs[0].set_title('Train - Index: {}, Label: {}'.format(random_index[0], train_labels[random_index[0]]))\n",
    "axs[1].imshow(val_image_set[random_index[1]], cmap='Greys')\n",
    "axs[1].set_title('Val - Index: {}, Label: {}'.format(random_index[1], val_labels[random_index[1]]))\n",
    "axs[2].imshow(test_image_set[random_index[2]], cmap='Greys')\n",
    "axs[2].set_title('Test - Index: {}, Label: {}'.format(random_index[2], test_labels[random_index[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a smaller test set\n",
    "### Randomly select subframes from a larger test set to make a smaller test set. In this example, we choose our test set to be 100 random subframes from our 200 subframe generated test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_set_small, test_labels_small = generate_test_data(test_image_set, test_labels, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_set_small.shape, test_labels_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eXXQBrxY6kV"
   },
   "source": [
    "## Test model functionality\n",
    "### Before running any models, verify an image can be passed through the model and produce an output. If not, there's a bug somewhere in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTdD6mn4ZfN3"
   },
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "image = train_image_set[0].reshape(1,1,SIZE,SIZE)\n",
    "model_output = model(torch.Tensor(image)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5OtELUwdYOb",
    "outputId": "39ec8e8b-16e9-4fb8-a316-2e948c278652"
   },
   "outputs": [],
   "source": [
    "image.shape, model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "n4uiDNxTdYQ1",
    "outputId": "1adff42d-54c0-4306-d977-0a17d82e811c"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image[0, 0], cmap='Greys')\n",
    "model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count trainable parameters\n",
    "### As model's become more complex, the number of parameters increase and training will take more time. The default model has approximately 8M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDaa2BRwe9zH",
    "outputId": "4ae024b6-c0dd-49e8-a0fb-0254d715e45e"
   },
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdySv7NzfSWG"
   },
   "source": [
    "## Establish baseline\n",
    "### Baseline Accuracy = 50%; randomly choosing labels\n",
    "### If the model cannot outperform the baseline, then the model isn't learning. Try debugging data and model if the model's accuracy is at baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWQjtnorjNZ-"
   },
   "source": [
    "## Set hyperparameters\n",
    "### A personal rule of thumb is for the batch size to be 1/100th the size of the training set. This allows the model to update itself 100 times each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKWc7i5WjZRp",
    "outputId": "4721c61b-b189-44bc-b24d-ddcbad02df06"
   },
   "outputs": [],
   "source": [
    "dataloader_params = {\n",
    "    'batch_size': 1,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "num_epochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4rNS3Hfrb7b"
   },
   "source": [
    "## Train and validate model\n",
    "### Since there isn't a substantial amount of data, the model may not learn to a high degree (i.e. accuracy may be around baseline). However, the loss should be decreasing, meaning it is learning a little and is properly functioning!\n",
    "### In addition, the loss function, confusion matrix, saliency map, and final testing cells below are just illustrations for running code.\n",
    "### Training should take less than two minutes with the generated sata set and default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model_return = build_model(train_image_set, \n",
    "                                 train_labels, \n",
    "                                 val_image_set, \n",
    "                                 val_labels, \n",
    "                                 dataloader_params, \n",
    "                                 num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, lst_train_loss, lst_val_loss, lst_accuracy = build_model_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5GwVP61z35A"
   },
   "source": [
    "## Plot loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "0NJQVYvt5Tgp",
    "outputId": "9300b8c9-68fe-4324-f222-37cc0e4bae26"
   },
   "outputs": [],
   "source": [
    "plot_metrics(num_epochs, lst_train_loss, lst_val_loss, lst_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrIDlFQm4UBW"
   },
   "source": [
    "## Plot confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs_small, test_predictions_small, cm = confusion_matrix(model, \n",
    "                                                                  test_image_set_small, \n",
    "                                                                  test_labels_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze saliency maps\n",
    "### We can determine what features the model decides is most important when classifying subframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(test_labels_small.shape[0])\n",
    "sal_map = saliency_map(model, test_image_set_small[index], test_labels_small[index], index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRkj7ALs6Fim"
   },
   "source": [
    "## Analyze incorrect images\n",
    "### By analyzing trends in incorrect images, we can determine what our model is struggling with and make appropriate adjustments to our data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Jyc7LFNu6aeU",
    "outputId": "edc638d9-513d-4616-ed95-fd207095fb78"
   },
   "outputs": [],
   "source": [
    "incorrect = check_incorrect_image(test_image_set_small, \n",
    "                                  test_labels_small, \n",
    "                                  test_outputs_small, \n",
    "                                  test_predictions_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test: check predictions on full subframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = np.load('saved_generated_datasets/final_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_blob = final_test['blob']\n",
    "final_test_non_blob = final_test['non_blob']\n",
    "final_test_median = final_test['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, final_test_blob.shape[0], 3)\n",
    "sal_map_blob = saliency_map(model, final_test_blob[indices[0]], 1, indices[0])\n",
    "sal_map_non_blob = saliency_map(model, final_test_non_blob[indices[1]], 0, indices[1])\n",
    "sal_map_median = saliency_map(model, final_test_median[indices[2]], 1, indices[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'example_model.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Load Model\n",
    "### Now with a saved model,  it can be loaded onto other notebooks that have the script running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wfc3_ir_blob_class_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model.load_state_dict(torch.load('example_model.torch'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wfc3-ir-blob-class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
